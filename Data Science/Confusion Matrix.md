<p align='right'><a align="right" href="https://github.com/KIRANKUMAR7296/Library/blob/main/Interview.md">Back to Questions</a></p>

# Confusion Matrix

![Confusion Matrix](Image/ConfusionMatrix.jpeg)

### True Situations

**TP** : True Positive ( Actual is True | Prediction is also True )
**TN** : True Negative ( Actual is False | Prediction is also False )


### False Situations 
**FP** : False Positive ( **Type I** Error ) ( Actual is False | but Prediction is True )
**FN** : False Negative ( **Type II** Error ) ( Actual is True | but Prediction is False )


### Accuracy 
- TP + TN / ( TP + FP + FN + TN )

### Precision  
- How many Correct True Predictions where Actually True ?  
- TP / ( TP + FP )

### Sensitivity | Recall | True Positive Rate ( TPR ) 
- How many Actal True are Predicted Correctly ?  
- TP / ( TP + FN )

### Specificity | False Positive Rate ( FPR ) 
- TN / ( TN + FP )

### F1
- Harmonic Mean
- F1 = 2 * ( Precision * Recall ) / ( Precision + Recall )

<p align='right'><a align="right" href="https://github.com/KIRANKUMAR7296/Library/blob/main/Interview.md">Back to Questions</a></p>
