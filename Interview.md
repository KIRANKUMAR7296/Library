### 1. Balancing **Bias** and **Variance**
- We try to make out **Model** more **Accurate** by **Tuning** and **Tweaking** the **Parameters**.
- But we cannot make a **100%** Accurate Model.
- **Prediction** ( Continuous ) and **Classification** Models, can never be **Error Free**.

> **Y** = f ( **x** ) + **e**

**Y** : Response Variable | Dependent Variable

**x** : Independent Variable

**e** : Irreducible Error

- Even we make a **100%** Accurate Estimate of **f(x)**, Our Model won't be **Error Free**, known as **Irreducible Error**

### 2. Decision Tree
- **Decision Tree** is used for both **Regression** and **Classification**
- **Upside Down** Approach
- **Root** at **Top**
- Decisiona are **Nodes**
- Splits of Trees are **Edges** | **Branches**
- Terminal Node is a **Leaf**
- **Decision** Tree Algorithms are referred to as **CART** ( **Classification** and **Regression Tree** )
- Growing a tree involves deciding on **which features to choose** and **what conditions to use** for splitting.
- We should also know when to **Stop**
