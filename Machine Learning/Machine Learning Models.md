# Machine Learning Models

### Supervised Learning

A. Regression

- Predict Dependent Variable on the basis of **Independent Features**

- Find **Relationship** between **Independent Variable** and **Dependent Variable**.

- Output is **Continuous**.

1. Linear Regression 

> Simple Linear Regression : Find the Line that **Fits** the Data.

> Multiple Linear Regression : Find the Plane of **Best Fit**.

> Polynomial Regression : Find a Curve for **Best Fit**. 
 
2. Decision Tree

- Nodes 

3. Random Forests (Ensemble Learning Technique)

- Multiple Decision Tree

- **Bootstrapped Data Sets** of Orignal Data and **Randomly** selecting **Subsets** at each step.
 
- Model Selectes the **Mode** of Decision Trees (Majority Voting)

- Reduces Risk of **Error** and **Overfitting**.

4. Neural Network

- Multi Layered Model inspired by **Human Brain**

- Nodes, Edges and Layers   

B. Classififcation

- Predict **Dependent Variable**(Categories of Labels) on the basis of **Independent Features**

- Find **Relationship** between **Independent Variable** and **Dependent Variable**.

- Output is **Discrete**

1. Logistic Regression 

- Probability of Finite Number of Outcomes.

- Output values can be between 0 and 1

2. Support Vector Machine

- Find **Hyperplane** in **N Dimensional Space** that can distinctly classify the data points.

3. Naive Bayes

- Probabilistic Machine Learning Model (Likelihood, Prior Probability and Posterior Probability)

4. Decision Tree

5. Random Forest

6. Neural Network 

All follow Same Process in Regression and Classification the only difference is Output 

> **Regression** Output : **Continuous**

> **Classification** Output : **Discrete**

 
### Unsupervised Learning

- Find **Patterns** and **Relationships** from Input Data without References (Labels)

A. Clustering

> Grouping of Data Points 

- Customer Segmentation | Fraud Detection | Document Classification

> Clustering Techniques

1. K Mean

2. Hierarchical
 
3. Density Based

B. Dimensionality Reduction

> Reducing the Number of **Irrelevant Features**

> Feature **Elimination** or Feature **Extraction**

Principal Component Analysis.
 
